{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment No. 4 (Optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write your implementation within the designated blocks:\n",
    "```python\n",
    "...\n",
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution\n",
    "...\n",
    "```\n",
    "\n",
    "Write your theoretical derivations within such blocks:\n",
    "```markdown\n",
    "**BEGIN Solution**\n",
    "\n",
    "<!-- >>> your derivation here <<< -->\n",
    "\n",
    "**END Solution**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\LaTeX$ in Jupyter\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to\n",
    "write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "\\begin{align}\n",
    "    left-hand-side\n",
    "        &= right-hand-side on line 1\n",
    "        \\\\\n",
    "        &= right-hand-side on line 2\n",
    "        \\\\\n",
    "        &= right-hand-side on the last line\n",
    "\\end{align}\n",
    "```\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly / outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will need to work through a modified version of\n",
    "the SVDD model (**support vector data description**) -- a model for outlier\n",
    "detection, and show some theoretical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have a dataset $x_1, \\ldots, x_l$ from some set $\\mathcal{X}$.\n",
    "\n",
    "We apply the kernel trick using the kernel $K \\colon \\mathcal{X} \\times \\mathcal{X}\n",
    "\\to \\mathbb{R}$ of the Hilbert space $\\bigl(\\mathcal{H}, \\langle \\cdot,\n",
    "\\cdot \\rangle\\big)$ with the feature mapping $\\phi(\\cdot)\\colon \\mathcal{X}\n",
    "\\to \\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that $\\nu \\in (0, 1)$, and $C_i > 0$ with $\\sum_{i=1}^l C_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDD model (kernelized) is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 pt.): Can $R$ be negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the SVDD problem with an extra constraint $R \\geq 0$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,, \\\\\n",
    "    & & & R \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R \\geq 0$ constraint is a nuisance.\n",
    "\n",
    "* Show, that if $(R, \\xi, h)$ has $R < 0$, then it **is not better** than a\n",
    "certain other feasible candidate $(\\hat{R}, \\hat{\\xi}, \\hat{h})$ with $\\hat{R} \\geq 0$.\n",
    "* Argue that it is, in fact, **redundant**, i.e. the problem formulations\n",
    "**with it** and **without it** have identical solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Let's look on objective functions for $(R < 0, \\xi, h)$. Thus, $|R| = -R \\rightarrow R = -|R|$\n",
    "$$\n",
    "-|R| + \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\xi_i \\geq -|R| + \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i (\\|\\phi(x_i) - h \\|^2 + |R|)$$\n",
    "$$ -|R| + \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i (\\|\\phi(x_i) - h \\|^2 + |R|)= \\frac{1}{\\nu}|R| - |R| + \\frac{1}{\\nu}\\sum_{i = 1}^{l} C_i \\|\\phi(x_i) - h \\|^2$$ \n",
    "$$ \\frac{1}{\\nu}|R| - |R| + \\frac{1}{\\nu}\\sum_{i = 1}^{l} C_i \\|\\phi(x_i) - h \\|^2> \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    " 2. Now we can finally write for objective function:\n",
    "$$-|R| + \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\xi_i  > \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\|\\phi(x_i) - h \\|^2$$\n",
    " 3. Let's look the other feasible candidate with $(\\hat{R} = 0, \\hat{\\xi}, \\hat{h} = h)$ with subject to $\\|\\phi(x_i) - h \\|^2 = \\hat{\\xi}_i$\n",
    "$$\n",
    "\\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\hat{\\xi}_i = \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\hat{\\xi}_i = \\frac{1}{\\nu} \\sum_{i = 1}^{l} C_i \\|\\phi(x_i) - h\\|^2  \n",
    "$$\n",
    " 4. From this and previous inequality we can see, that for some feasible candidate with $\\hat{R} \\geq 0$ we receive solution which is to be better, than the optimal one for $R < 0$. It's not guaranteed that the represented solution in second point to be optimal. Thus, we proved the first point of the task.\n",
    "\n",
    "* For $R \\in \\mathbb{R}$ condition $R \\geq 0$ is redundant, because for optimal solution will have $R \\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (2 pt.): Can $\\xi_i > 0$ for all $i$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argue if $(R, \\xi, h)$ is a solution, then $\\xi_i = 0$ for at least one $i=1,\\,\\ldots,\\,l$. Let $\\bar{\\xi} = \\min_{j=1}^l \\xi_j$.\n",
    "\n",
    "**HINT** Use an argument similar to Task $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose, we have solution $(R, \\xi, h)$. Let's denote as $k =  \\text{arg}\\min_{j=1}^l \\xi_j$ - index of minimal $\\xi_i$.\n",
    "2. Imagine for $\\forall i \\ \\xi_i > 0 \\rightarrow \\bar{\\xi} >0$. \n",
    "3. So for our objective function (let's denote as $\\mathcal{F}$), subject to $\\bar{\\xi} >0$, using denotation $C_i = |i = k| = \\bar{C}$:\n",
    "$$\n",
    "\\mathcal{F} = R + \\frac{1}{\\nu}\\sum_{i=1}^l C_i \\xi \n",
    "$$\n",
    "We can substract minimal $\\xi_i$ from sum:\n",
    "$$\n",
    "\\mathcal{F} = R + \\frac{1}{\\nu}\\bar{C}\\bar{\\xi} +  \\frac{1}{\\nu} \\sum_{i=1,i\\neq k}^l C_i \\xi \n",
    "$$\n",
    "4. Let's choose another point $(\\hat{R}, \\hat{\\xi}, h)$, such that:\n",
    "$$\\hat{R} = R + \\bar{\\xi}, \\hat{\\xi} = \\xi - \\bar{\\xi}$$\n",
    "where last equation must be interpreted as character subtraction.\n",
    "5. Point from 4. satisfies all given above conditions and minimal value for $\\hat{\\xi}_i = 0$.\n",
    "6. So, for objective function (let's denote as $\\hat{\\mathcal{F}}$):\n",
    "$$\n",
    "\\hat{\\mathcal{F}} = \\hat{R} + \\frac{1}{\\nu} \\sum_{i=1}^l C_i \\hat{\\xi}\n",
    "$$\n",
    "or using denotation for $(\\hat{R}, \\hat{\\xi}, h)$\n",
    "$$\n",
    "\\hat{\\mathcal{F}} = R + \\bar{\\xi} + \\frac{1}{\\nu} \\sum_{i=1}^l C_i (\\xi - \\bar{\\xi})\n",
    "$$\n",
    "7. Using that fact that minimal value for $\\xi_i = 0$ (denote index as $k$), we obtain:\n",
    "$$\n",
    "\\hat{\\mathcal{F}} = R + \\bar{\\xi} + \\frac{1}{\\nu} \\sum_{i=1, i \\neq k}^l C_i (\\xi - \\bar{\\xi}) =  R + \\bar{\\xi}(1 - \\frac{1}{\\nu} \\sum_{i=1, i \\neq k}^l C_i ) + \\frac{1}{\\nu}  \\sum_{i=1, i \\neq k}^l C_i \\xi\n",
    "$$\n",
    "$$\n",
    "\\hat{\\mathcal{F}}  =  R + \\bar{\\xi} +  \\frac{1}{\\nu}  \\sum_{i=1, i \\neq k}^l C_i \\xi - \\frac{1}{\\nu}(1 - \\bar{C})\\bar{\\xi} = \\mathcal{F} + (\\frac{1}{\\nu})\\bar{\\xi} < \\mathcal{F}\n",
    "$$\n",
    "8. From 7. we see, that $\\forall$ points with $\\bar{\\xi} > 0$ we can decrease value of objective function, by choosing new point with $\\bar{\\xi} = 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (2 pt.): The Lagrangian and KKT conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write out the Lagrangian function of the problem and write out the KKT conditions\n",
    "* Lagrangian\n",
    "* the first order conditions\n",
    "* the complementary slackness conditions\n",
    "* the primal and dual constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Langrangian $\\mathcal{L}$: \n",
    "$$\n",
    "\\mathcal{L} = R + \\frac{1}{\\nu}\\sum_{i = 1}^l  C_i\\xi_i  - \\sum_{i = 1}^l\\alpha_i(R + \\xi_i - \\|\\phi(x_i) - h \\|^2) - \\sum_{i = 1}^l \\beta_i \\xi_i\n",
    "$$\n",
    "* And KKT conditions:\n",
    "   1. First order conditions: \n",
    "   $$\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial \\xi_i} = \\frac{1}{\\nu}C_i - \\alpha_i - \\beta_i = 0 \\rightarrow \\frac{1}{\\nu}C_i - \\alpha_i = \\beta_i ,  i = \\overline{1,l}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial R} = 1 - \\sum_{i=1}^{l} \\alpha_i = 0 \\rightarrow \\sum_{i=1}^{l} \\alpha_i = 1\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial h} = \\sum_{i = 1}^{l} 2 \\alpha_i (\\phi(x_i) - h) = 0 \\rightarrow \\sum_{i = 1}^{l} 2 \\alpha_i \\phi(x_i)  - \\sum_{i = 1}^{l} 2 \\alpha_i h = 0 \\rightarrow \\sum_{i = 1}^{l}  \\alpha_i \\phi(x_i) - h \\sum_{i = 1}^{l} \\alpha_i = 0 \n",
    "   $$\n",
    "   Using first order condition above:\n",
    "   $$\n",
    "   h =  \\sum_{i = 1}^{l}  \\alpha_i \\phi(x_i)\n",
    "   $$\n",
    "   2. The complementary slackness conditions:\n",
    "   $$\n",
    "   \\alpha_i(R + \\xi_i - \\|\\phi(x_i) - h\\|^2) = 0 , i = \\overline{1,l}\\\\\n",
    "   $$\n",
    "   $$\n",
    "   \\beta_i \\xi_i = 0, i = \\overline{1,l}\n",
    "   $$\n",
    "   3. The primal and dual constrains: \n",
    "   $$\n",
    "   \\alpha_i \\geq 0, \\beta_i \\geq 0, i = \\overline{1,l} \\\\\n",
    "   $$\n",
    "   $$\n",
    "   R + \\xi_i - \\|\\phi(x_i) - h\\|^2 \\geq 0, \\xi_i \\geq 0\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (2 pt.): Simplifying the Lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down $h$ as a function of transformed input data and dual coefficients,\n",
    "and using the first order conditions rewrite the Lagrangian in such a way, that\n",
    "it only contains dual variables and evaluations of the kernel $K(\\cdot, \\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Expression for $h$ was written in previous task. Thus for the Lagrangian:\n",
    "$$\n",
    "\\mathcal{L} = R + \\frac{1}{\\nu}\\sum_{i = 1}^l  C_i\\xi_i  - \\sum_{i = 1}^l\\alpha_i(R + \\xi_i - \\|\\phi(x_i) - h \\|^2) - \\sum_{i = 1}^l \\beta_i \\xi_i\n",
    "$$\n",
    "2. Last part of sum from KKT conditions equals null, so continuing rewriting:\n",
    "$$\n",
    "\\mathcal{L} = R + \\frac{1}{\\nu}\\sum_{i = 1}^l  C_i\\xi_i  - \\sum_{i = 1}^l(\\alpha_i R + \\alpha_i \\xi_i) + \\sum_{i = 1}^l\\alpha_i\\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    "3. Using KKT condition $\\sum_{i=1}^{l} \\alpha_i = 1$:\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{\\nu}\\sum_{i = 1}^l  C_i\\xi_i  - \\sum_{i = 1}^l\\alpha_i \\xi_i + \\sum_{i = 1}^l\\alpha_i\\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    "4. Now we to simplify first two parts of the sum, using the following KKT condtion $\\frac{1}{\\nu}C_i - \\alpha_i = \\beta_i$:\n",
    "$$\n",
    "\\frac{1}{\\nu}\\sum_{i = 1}^l  C_i\\xi_i  - \\sum_{i = 1}^l\\alpha_i \\xi_i = \\sum_{i = 1}^l (\\frac{1}{\\nu}C_i - \\alpha_i ) \\xi_i = \\sum_{i = 1}^l \\beta_i \\xi_i\n",
    "$$\n",
    "5. From 4., we assume:\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i = 1}^l \\beta_i \\xi_i + \\sum_{i = 1}^l\\alpha_i\\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    "which, same as in 1. comes to:\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i = 1}^l\\alpha_i\\|\\phi(x_i) - h \\|^2\n",
    "$$\n",
    "6. Now let's rewrite the norm representation:\n",
    "$$\n",
    "\\|\\phi(x_i) - h \\|^2 = \\big(\\langle\\phi(x_i), \\phi(x_i) \\rangle - 2 \\langle h, \\phi(x_i) \\rangle + \\langle h,h \\rangle \\big)\n",
    "$$\n",
    "7. From KKT condition $h = \\sum_{i = 1}^{l}  \\alpha_i \\phi(x_i)$, we receive the resulting equality for the Lagrangian : \n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i = 1}^{l}\\alpha_i K(x_i;x_i) - \\sum_{i,j = 1}^{l} \\alpha_i \\alpha_jK(x_i;x_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 (2 pt.): The dual problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carefully eliminate $\\beta_i$ from the KKT conditions, and write\n",
    "down the inequality constraints for the dual variables $\\alpha_i$,\n",
    "implied by the FOC.\n",
    "\n",
    "* Combine your results into dual problem (minimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. We will use the following KKT conditions:\n",
    "  $$\n",
    "  \\alpha_i \\geq 0, i = \\overline{1,l} \n",
    "  $$\n",
    "  $$\n",
    "  \\beta_i = \\frac{1}{\\nu}C_i - \\alpha_i, i = \\overline{1,l} \n",
    "  $$\n",
    "  2. From 1., using one more KKT condition $\\beta_i \\geq 0, i = \\overline{1,l} $ we obtain:\n",
    "  $$\n",
    "  0 \\leq \\alpha_i \\leq \\frac{1}{\\nu}C_i\n",
    "  $$\n",
    "* 1. Combining results from previous tasks into dual minimization problem we receive: \n",
    "    $$\n",
    "    \\min \\sum_{i,j = 1}^{l} \\alpha_i \\alpha_jK(x_i;x_j) - \\sum_{i = 1}^{l}\\alpha_i K(x_i;x_i) \\\\\n",
    "\\text{subject to} \\ \\ \\ \\ \\   \\sum_{i=1}^l \\alpha_i = 1,\\\\\n",
    "    \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\  0 \\leq \\alpha_i \\leq \\frac{1}{\\nu}C_i\n",
    "    $$\n",
    "  2. Remaining KKT conditions are fully satisfied during Kernel simplification of form of the Langrangian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, you have solved the dual and have optimal $(\\alpha^*_i)_{i=1}^l$ and\n",
    "$ h^* = \\sum_{i=1}^l \\alpha^*_i \\phi(x_i)$.\n",
    "\n",
    "Let $M = \\{i\\colon \\alpha^*_i \\in \\left(0, \\tfrac{C_i}{\\nu}\\right)\\}$ and suppose $M \\neq \\emptyset$.\n",
    "\n",
    "* Derive the expression for the optimal value of $R$ from this and the\n",
    "complementary sclackness conditions.\n",
    "\n",
    "* Write out the decision function for an arbitrary $x\\in \\mathcal{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Using the following KKT conditions:\n",
    "  $$\n",
    "  \\beta_i \\geq 0, i = \\overline{1,l} \n",
    "  $$\n",
    "  and  \n",
    "  $$\n",
    "  \\beta_i = \\frac{1}{\\nu} C_i - \\alpha_i \\rightarrow \\alpha_i \\geq 0, i = \\overline{1,l}\n",
    "  $$\n",
    "  then \n",
    "  $$\n",
    "  \\beta_i \\xi_i = 0 \\rightarrow \\xi_i = 0\n",
    "  $$\n",
    "  2. For optimal value of $R$ (denoted as $\\hat{R}$) comes from complementary slackness conditions:\n",
    "  $$\n",
    "  \\alpha_i(R + \\xi_i - \\|\\phi(x_i) - h \\|^2) = 0 \\rightarrow |\\alpha_i \\geq 0| \\rightarrow \n",
    "  $$\n",
    "  $$\n",
    "  \\rightarrow R + \\xi_i - \\|\\phi(x_i) - h \\|^2 = 0  \\rightarrow |\\xi_i = 0| \\rightarrow\n",
    "  $$\n",
    "  $$\n",
    "  \\rightarrow \\hat{R} = \\|\\phi(x_i) - h\\|^2\n",
    "  $$\n",
    "* 1. Decision function for an arbitrary $x\\in \\mathcal{X}$ looks like:\n",
    "$$\n",
    "\\hat{f}(x) = \\text{sgn}(R(x) - \\hat{R}(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.1 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ we have $\\|\\phi(x_i) - h\\|^2 < R$.\n",
    "We will call this point **inlier**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for such a point?\n",
    "* Show that $1-\\nu$ upper-bounds the sum of weights $C_i$ for the **inlier** points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Let's consider for $i$-th point $x_i$, which supposed to be inlier:\n",
    "  $$\n",
    "  \\|\\phi(x_i) - h\\|^2 = R - \\Delta_i, \\Delta_i > 0, i = \\overline{1,l}\n",
    "  $$\n",
    "  we have the following complementary slackness conditions: \n",
    "  $$\n",
    "  \\alpha_i(R + \\xi_i - \\|\\phi(x_i) - h \\|^2) = 0\n",
    "  $$\n",
    "  2. From last equation of 1., we receive:\n",
    "  $$\n",
    "  \\alpha_i(\\xi_i + \\Delta_i) = 0 \n",
    "  $$\n",
    "  from which we conclude, that $a_i = 0$.\n",
    "  3. Using KKT condition:\n",
    "  $$\n",
    "  \\beta_i  = \\frac{1}{\\nu}C_i - \\alpha_i \\rightarrow \\beta_i = \\frac{1}{\\nu}C_i\n",
    "  $$\n",
    "  4. Thus, the resulting values of $\\alpha_i$ and $\\beta_i$ are:\n",
    "  $$\n",
    "  \\alpha_i = 0, \\beta_i = \\frac{1}{\\nu} C_i\n",
    "  $$\n",
    "* 1. For inliers upper-bound on the sum of weights $C_i$, using rewrited condition:\n",
    "  $$\n",
    "  \\alpha_i + \\beta_i  = \\frac{1}{\\nu}C_i \\rightarrow  \\frac{1}{\\nu} = \\frac{1}{\\nu} \\sum_{i = 1}^{l}{C_i} =  \\sum_{i=1}^l \\alpha_i + \\sum_{i=1}^l \\beta_i\n",
    "  $$\n",
    "  2. Let's split set all points $x_i$, denoted as $\\mathcal{X}$ into inliers and remaining points, denoted as $\\mathcal{X}_i$ and $\\mathcal{X}_o$ respectively, for which we can write: \n",
    "  $$\n",
    "  \\frac{1}{\\nu} \\sum_{i = 1}^{l}{C_i} = \\sum_{x_i \\in \\mathcal{X}_o }\\beta_i + \\sum_{x_i \\in \\mathcal{X}_i }\\beta_i + 1\n",
    "  $$\n",
    "  3. Using result of previous task, we can rewrite $\\beta_i$ for inliers:\n",
    "  $$\n",
    "  \\frac{1}{\\nu} \\sum_{i = 1}^{l}{C_i} = \\sum_{x_i \\in \\mathcal{X}_o }\\beta_i + \\sum_{x_i \\in \\mathcal{X}_i }\\frac{1}{\\nu}C_i + 1\n",
    "  $$\n",
    "  4. So for sum of $C_i$ for inliers we receive:\n",
    "  $$\n",
    "  \\sum_{x_i \\in \\mathcal{X}_i }\\frac{1}{\\nu}C_i  = 1 - \\nu - \\sum_{x_i \\in \\mathcal{X}_o }\\nu \\beta_i \\leq 1 - \\nu\n",
    "  $$\n",
    "  Hence, we proved the upper-bound by $1 - \\nu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.2 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ it holds that $\\|\\phi(x_i) - h \\|^2 > R$.\n",
    "Such points are called **outliers**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for these points?\n",
    "* Argue that the sum of weights $C_i$ for the **outliers** is upper bounded by $\\nu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 1. Using same techniques, as in a previous task we assume, that: \n",
    "  $$\n",
    "  \\beta_i = 0 \n",
    "  $$\n",
    "  2. and then \n",
    "  $$\n",
    "  \\alpha_i = \\frac{1}{\\nu} C_i\n",
    "  $$\n",
    "\n",
    "* 1.Using same denotations for point split, like in task for inliers (with that remark, that now, what was denoted as inliers now denotes set of non-outliers poitns), we can write condition on $a_i$:\n",
    "  $$\n",
    "  \\sum_{i=1}^l \\alpha_i = \\sum_{x_i \\in \\mathcal{X}_o} \\alpha_i + \\sum_{x_i \\in \\mathcal{X}_i} \\alpha_i = 1 \n",
    "  $$\n",
    "  2. Continuing, subsituting $\\alpha_i = \\frac{1}{\\nu} C_i$ for outliers:\n",
    "  $$\n",
    "  1 = \\sum_{x_i \\in \\mathcal{X}_o}       \\frac{1}{\\nu}C_i + \\sum_{x_i \\in \\mathcal{X}_i} \\alpha_i \n",
    "  $$\n",
    "  3. Finally:\n",
    "  $$\n",
    "  \\sum_{x_i \\in \\mathcal{X}_o} C_i = \\nu - \\nu \\sum_{x_i \\in \\mathcal{X}_i} \\alpha_i < \\nu\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.3: Very small $\\nu$ (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\nu < C_i$ for all $i=1,\\,\\ldots,\\,l$. Show that\n",
    "there are **no outliers** in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose, we have outliers in this case and $\\nu < C_i$ performed for them.\n",
    "2. So for $\\alpha_i$ for this outliers we can write down:\n",
    "   $$\n",
    "   \\alpha_i = \\frac{1}{\\nu}C_i = \\frac{C_i}{\\nu} > 1 \n",
    "   $$\n",
    "3. But it's known from condition for sum of $a_i$, that $a_i$ can't be greater than 1, otherwise KKT conditions are not satisfied. \n",
    "4. Contradiction, so there are no outliners in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.4 (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $C_i = \\tfrac1l$. Please, describe how $\\nu$ is related to the\n",
    "outliers in the dataset, given the analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we know from (7.2) sum of $C_i$ for outliers is upper-bounded by $\\nu$\n",
    "2. Due, to that fact that all $C_i = \\frac{1}{l}$, we can easily find the sum $ \\sum_{x_i \\in \\mathcal{X}_o} C_i$, which equals to $n \\frac{1}{l}$, where $n$ denotes number of outliers. \n",
    "3. From the facts given above, we can conclude that number of outliers $n$ is upper-bounded by value $l \\nu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
